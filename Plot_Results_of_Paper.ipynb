{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "datasets = {\n",
        "    'Cora': {\n",
        "        'GCN': [(100, 0.45331318974494933, 0.024756455654897046),\n",
        "                (500, 0.23856463730335237, 0.014240488795972095),\n",
        "                (1000, 0.16623241305351258, 0.007939122345212673)],\n",
        "        'GAT': [(100, 0.4247232496738434, 0.03526640259761619),\n",
        "                (500, 0.2265682637691498, 0.01985088532073069),\n",
        "                (1000, 0.17245431542396544, 0.009573755414000502)],\n",
        "        'GraphSAGE': [(100, 0.5282434463500977, 0.02662578778883726),\n",
        "                      (500, 0.2611788988113403, 0.011081628608493049),\n",
        "                      (1000, 0.17424136102199556, 0.01182381363000765)]\n",
        "    },\n",
        "    'Reddit': {\n",
        "        'GCN': [(100, 0.6638607740402221, 0.04893704996814368),\n",
        "                (500, 0.39872702956199646, 0.031492316429588926),\n",
        "                (1000, 0.25180703699588775, 0.027561228403015604),\n",
        "                (5000, 0.11390651613473893, 0.005034993087847129),\n",
        "                (10000, 0.09257184416055679, 0.0022101293663993942),\n",
        "                (50000, 0.07923970818519592, 0.0012036254204641356)],\n",
        "        'GAT': [(100, 0.74683119058609, 0.07390229955504421),\n",
        "                (500, 0.7327924728393554, 0.032305080962742136),\n",
        "                (1000, 0.6507743716239929, 0.03551110132146038),\n",
        "                (5000, 0.41393967866897585, 0.03768536853473231),\n",
        "                (10000, 0.3230024456977844, 0.04470648755372255),\n",
        "                (50000, 0.1848956435918808, 0.019780347600618014)],\n",
        "        'GraphSAGE': [(100, 0.7809877634048462, 0.03528722600583161),\n",
        "                      (500, 0.5848131775856018, 0.019288915605109015),\n",
        "                      (1000, 0.452128005027771, 0.02889391719691232),\n",
        "                      (5000, 0.20689032971858978, 0.0011023282183319496),\n",
        "                      (10000, 0.15035432875156401, 0.002545760565421577),\n",
        "                      (50000, 0.07758742719888687, 0.00033193818017408463)]\n",
        "    },\n",
        "    'QM9': {\n",
        "        'GCN': [(100, 2.010820424542159, 0.10295508270121849),\n",
        "                (500, 1.8500684509941885, 0.05619516912623903),\n",
        "                (1000, 1.7505244721264597, 0.05373075402225386),\n",
        "                (5000, 1.5587026009932707, 0.04819121632473715),\n",
        "                (10000, 1.5350490051916001, 0.03816020820016992),\n",
        "                (50000, 1.5022996501628227, 0.018802712780239785)],\n",
        "        'GAT': [(100, 1.1261, 0.2953),\n",
        "                (500, 1.0342, 0.1615),\n",
        "                (1000, 0.9506, 0.0545),\n",
        "                (5000, 0.9287, 0.0138),\n",
        "                (10000, 0.8948, 0.0240),\n",
        "                (50000, 0.9009, 0.0140)],\n",
        "        'GraphSAGE': [(100, 2.166804970126863, 0.2843937350060123),\n",
        "                      (500, 1.7563000858777307, 0.12584696522988958),\n",
        "                      (1000, 1.624144569206937, 0.0746565879268105),\n",
        "                      (5000, 1.4869281925242805, 0.03545359297761349),\n",
        "                      (10000, 1.457223077500945, 0.023084938119480234),\n",
        "                      (50000, 1.430181429788361, 0.04495243871141515)]\n",
        "    },\n",
        "    'Facebook': {\n",
        "        'GCN': [(100, 0.1146, 0.0103),\n",
        "                (500, 0.0719, 0.0032),\n",
        "                (1000, 0.0555, 0.0080)],\n",
        "        'GAT': [(100, 0.1671, 0.0249),\n",
        "                (500, 0.0966, 0.0088),\n",
        "                (1000, 0.0777, 0.0086)],\n",
        "        'GraphSAGE': [(100, 0.14081752453760424, 0.018460682369960364),\n",
        "                      (500, 0.05991271242726692, 0.01133794980311604),\n",
        "                      (1000, 0.0428319653077297, 0.005503937151818257)]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Fitting functions\n",
        "def fit_linear_model(x, err, std):\n",
        "    \"\"\"\n",
        "    Fit a weighted linear model using inverse variance weights\n",
        "\n",
        "    Args:\n",
        "        x: Independent variable (transformation of n)\n",
        "        err: Error measurements\n",
        "        std: Standard deviations of error measurements\n",
        "\n",
        "    Returns:\n",
        "        tuple: (intercept, slope, weighted RSS, weighted MSE, weighted R^2)\n",
        "    \"\"\"\n",
        "    A = np.vstack([np.ones_like(x), x]).T\n",
        "    weights = 1 / std**2  # Using inverse variance as weights\n",
        "    W = np.diag(weights)\n",
        "\n",
        "    # Weighted least squares\n",
        "    theta = np.linalg.inv(A.T @ W @ A) @ A.T @ W @ err\n",
        "    fit = A @ theta\n",
        "\n",
        "    # Weighted metrics\n",
        "    weighted_residuals = weights * (err - fit)**2\n",
        "    weighted_rss = np.sum(weighted_residuals)\n",
        "    weighted_mse = np.mean(weighted_residuals)\n",
        "\n",
        "    # Weighted R^2 calculation\n",
        "    weighted_mean = np.sum(weights * err) / np.sum(weights)\n",
        "    weighted_total_ss = np.sum(weights * (err - weighted_mean)**2)\n",
        "    weighted_r2 = 1 - weighted_rss / weighted_total_ss\n",
        "\n",
        "    return theta[0], theta[1], weighted_rss, weighted_mse, weighted_r2\n",
        "\n",
        "def fit_power_law(n, err, std):\n",
        "    \"\"\"\n",
        "    Fit a power law model using weighted curve_fit\n",
        "\n",
        "    Args:\n",
        "        n: Sample sizes\n",
        "        err: Error measurements\n",
        "        std: Standard deviations of error measurements\n",
        "\n",
        "    Returns:\n",
        "        tuple: (gamma, c, weighted RSS, weighted MSE, weighted R^2)\n",
        "    \"\"\"\n",
        "    def func(n, gamma, c):\n",
        "        return c + 1 / n**gamma\n",
        "\n",
        "    # Use weights based on standard deviations, with no restrictive bounds\n",
        "    weights = 1 / std**2\n",
        "    popt, pcov = curve_fit(func, n, err, sigma=std, absolute_sigma=True, bounds=(0, np.inf))\n",
        "    gamma, c = popt\n",
        "\n",
        "    # Calculate fit\n",
        "    fit = func(n, gamma, c)\n",
        "\n",
        "    # Weighted metrics\n",
        "    weighted_residuals = weights * (err - fit)**2\n",
        "    weighted_rss = np.sum(weighted_residuals)\n",
        "    weighted_mse = np.mean(weighted_residuals)\n",
        "\n",
        "    # Weighted R^2\n",
        "    weighted_mean = np.sum(weights * err) / np.sum(weights)\n",
        "    weighted_total_ss = np.sum(weights * (err - weighted_mean)**2)\n",
        "    weighted_r2 = 1 - weighted_rss / weighted_total_ss\n",
        "\n",
        "    return gamma, c, weighted_rss, weighted_mse, weighted_r2\n",
        "\n",
        "# Gather all results\n",
        "rows = []\n",
        "for dataset, models in datasets.items():\n",
        "    for model, data in models.items():\n",
        "        n, err, std = zip(*data)\n",
        "        n, err, std = np.array(n), np.array(err), np.array(std)\n",
        "\n",
        "        # Fit models with consistent weighting\n",
        "        c_sqrt, b_sqrt, rss_sqrt, mse_sqrt, r2_sqrt = fit_linear_model(1 / np.sqrt(n), err, std)\n",
        "        c_n, b_n, rss_n, mse_n, r2_n = fit_linear_model(1 / n, err, std)\n",
        "        c_log, b_log, rss_log, mse_log, r2_log = fit_linear_model(1 / np.log(n), err, std)\n",
        "        gamma, c_gamma, rss_gamma, mse_gamma, r2_gamma = fit_power_law(n, err, std)\n",
        "\n",
        "        rows.append({\n",
        "            'Dataset': dataset,\n",
        "            'Model': model,\n",
        "            'c_1/sqrt(n)': c_sqrt,\n",
        "            'b_1/sqrt(n)': b_sqrt,\n",
        "            'RSS_1/sqrt(n)': rss_sqrt,\n",
        "            'MSE_1/sqrt(n)': mse_sqrt,\n",
        "            'R2_1/sqrt(n)': r2_sqrt,\n",
        "            'c_1/n': c_n,\n",
        "            'b_1/n': b_n,\n",
        "            'RSS_1/n': rss_n,\n",
        "            'MSE_1/n': mse_n,\n",
        "            'R2_1/n': r2_n,\n",
        "            'c_1/log(n)': c_log,\n",
        "            'b_1/log(n)': b_log,\n",
        "            'RSS_1/log(n)': rss_log,\n",
        "            'MSE_1/log(n)': mse_log,\n",
        "            'R2_1/log(n)': r2_log,\n",
        "            'c_1/n^gamma': c_gamma,\n",
        "            'RSS_1/n^gamma': rss_gamma,\n",
        "            'MSE_1/n^gamma': mse_gamma,\n",
        "            'R2_1/n^gamma': r2_gamma,\n",
        "            'gamma': gamma\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Find best fit for each model & dataset based on R^2\n",
        "df['Best_Fit'] = df[['R2_1/sqrt(n)', 'R2_1/n', 'R2_1/log(n)', 'R2_1/n^gamma']].idxmax(axis=1)\n",
        "df['Best_Fit'] = df['Best_Fit'].str.replace('R2_', '')\n",
        "\n",
        "# Generate LaTeX table\n",
        "latex_code = \"\\\\begin{table}[ht]\\n\\\\centering\\n\"\n",
        "latex_code += \"\\\\caption{Comparison of Fit Metrics Across All Models and Datasets (Weighted Analysis)}\\n\"\n",
        "latex_code += (\"\\\\begin{tabular}{ll\"\n",
        "               \"|ccc|ccc|ccc|ccc|c|c}\\n\\\\hline\\n\")\n",
        "latex_code += (\"\\\\multirow{2}{*}{Dataset} & \\\\multirow{2}{*}{Model} \"\n",
        "               \"& \\\\multicolumn{3}{c|}{$c_1 + \\\\frac{\\\\alpha}{\\\\sqrt{n}}$} \"\n",
        "               \"& \\\\multicolumn{3}{c|}{$c_2 + \\\\frac{\\\\beta}{n}$} \"\n",
        "               \"& \\\\multicolumn{3}{c|}{$c_3 + \\\\frac{\\\\delta}{\\\\log n}$} \"\n",
        "               \"& \\\\multicolumn{3}{c|}{$c_4 + \\\\frac{1}{n^{\\\\gamma}}$} & $\\\\gamma$ & Best Fit \\\\\\\\\\n\")\n",
        "latex_code += (\" & & RSS & MSE & R$^2$\"\n",
        "               \" & RSS & MSE & R$^2$\"\n",
        "               \" & RSS & MSE & R$^2$\"\n",
        "               \" & RSS & MSE & R$^2$ & & \\\\\\\\\\n\\\\hline\\n\")\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    latex_code += (f\"{row['Dataset']} & {row['Model']} & \"\n",
        "                   f\"{row['RSS_1/sqrt(n)']:.2e} & {row['MSE_1/sqrt(n)']:.2e} & {row['R2_1/sqrt(n)']:.3f} & \"\n",
        "                   f\"{row['RSS_1/n']:.2e} & {row['MSE_1/n']:.2e} & {row['R2_1/n']:.3f} & \"\n",
        "                   f\"{row['RSS_1/log(n)']:.2e} & {row['MSE_1/log(n)']:.2e} & {row['R2_1/log(n)']:.3f} & \"\n",
        "                   f\"{row['RSS_1/n^gamma']:.2e} & {row['MSE_1/n^gamma']:.2e} & {row['R2_1/n^gamma']:.3f} & \"\n",
        "                   f\"{row['gamma']:.3f} & {row['Best_Fit']} \\\\\\\\\\n\")\n",
        "\n",
        "latex_code += \"\\\\hline\\n\\\\end{tabular}\\n\"\n",
        "latex_code += \"\\\\label{tab:comparison_all_models_weighted}\\n\\\\end{table}\\n\"\n",
        "\n",
        "# Save to .tex file\n",
        "with open(\"final_comparison_table_weighted.tex\", \"w\") as f:\n",
        "    f.write(latex_code)\n",
        "\n",
        "print(\"✅ LaTeX table saved as final_comparison_table_weighted.tex\")\n",
        "\n",
        "# Also create a summary dataframe with just the best fit information and gamma values\n",
        "summary_df = df[['Dataset', 'Model', 'Best_Fit', 'gamma']]\n",
        "print(\"\\nSummary of best fits:\")\n",
        "print(summary_df)\n",
        "\n",
        "# Create a scatter plot to visually check fits for each dataset and model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def create_fit_plots():\n",
        "    for dataset, models in datasets.items():\n",
        "        fig, axs = plt.subplots(1, len(models), figsize=(15, 5), sharey=True)\n",
        "        fig.suptitle(f'Model Fits for {dataset} Dataset')\n",
        "\n",
        "        for i, (model_name, data) in enumerate(models.items()):\n",
        "            ax = axs[i] if len(models) > 1 else axs\n",
        "            n, err, std = zip(*data)\n",
        "            n, err, std = np.array(n), np.array(err), np.array(std)\n",
        "\n",
        "            # Get fit parameters from dataframe\n",
        "            model_row = df[(df['Dataset'] == dataset) & (df['Model'] == model_name)].iloc[0]\n",
        "\n",
        "            # Create dense x range for smooth curve plotting\n",
        "            x_dense = np.linspace(min(n), max(n), 100)\n",
        "\n",
        "            # Plot data points with error bars\n",
        "            ax.errorbar(n, err, yerr=std, fmt='o', label='Data')\n",
        "\n",
        "            # Plot fits\n",
        "            c1, b1 = model_row['c_1/sqrt(n)'], model_row['b_1/sqrt(n)']\n",
        "            ax.plot(x_dense, c1 + b1/np.sqrt(x_dense), '--', label=r'$c + \\frac{\\alpha}{\\sqrt{n}}$')\n",
        "\n",
        "            c2, b2 = model_row['c_1/n'], model_row['b_1/n']\n",
        "            ax.plot(x_dense, c2 + b2/x_dense, '-.', label=r'$c + \\frac{\\beta}{n}$')\n",
        "\n",
        "            c3, b3 = model_row['c_1/log(n)'], model_row['b_1/log(n)']\n",
        "            ax.plot(x_dense, c3 + b3/np.log(x_dense), ':', label=r'$c + \\frac{\\delta}{\\log{n}}$')\n",
        "\n",
        "            gamma, c4 = model_row['gamma'], model_row['c_1/n^gamma']\n",
        "            ax.plot(x_dense, c4 + 1/x_dense**gamma, '-', label=r'$c + \\frac{1}{n^{\\gamma}}$')\n",
        "\n",
        "            ax.set_title(f'{model_name}')\n",
        "            ax.set_xlabel('Sample Size (n)')\n",
        "            if i == 0:\n",
        "                ax.set_ylabel('Error')\n",
        "            ax.set_xscale('log')\n",
        "            ax.grid(True)\n",
        "            ax.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{dataset}_fits.png\", dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "try:\n",
        "    create_fit_plots()\n",
        "    print(\"✅ Created visualization plots for all datasets\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating plots: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIgXdYp49OFr",
        "outputId": "de4efef8-18fe-43bf-d67b-9eb3918232fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LaTeX table saved as final_comparison_table_weighted.tex\n",
            "\n",
            "Summary of best fits:\n",
            "     Dataset      Model   Best_Fit      gamma\n",
            "0       Cora        GCN   1/log(n)   0.242669\n",
            "1       Cora        GAT   1/log(n)   0.245456\n",
            "2       Cora  GraphSAGE   1/log(n)   0.220236\n",
            "3     Reddit        GCN  1/sqrt(n)   0.304053\n",
            "4     Reddit        GAT   1/log(n)   0.120367\n",
            "5     Reddit  GraphSAGE   1/log(n)   0.226867\n",
            "6        QM9        GCN   1/log(n)   0.129481\n",
            "7        QM9        GAT  1/sqrt(n)   0.360203\n",
            "8        QM9  GraphSAGE  1/sqrt(n)   0.145765\n",
            "9   Facebook        GCN   1/log(n)  10.794176\n",
            "10  Facebook        GAT   1/log(n)  10.796341\n",
            "11  Facebook  GraphSAGE  1/sqrt(n)   0.449356\n",
            "✅ Created visualization plots for all datasets\n"
          ]
        }
      ]
    }
  ]
}